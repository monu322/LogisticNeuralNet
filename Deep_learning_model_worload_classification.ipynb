{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_learning_model_worload_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M9Zmrngeql2"
      },
      "source": [
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqkLEGO8e_Q3",
        "outputId": "19c0f413-0155-4c8d-973f-053cd0426387"
      },
      "source": [
        "!wget https://monujohn.com/EEGdata/WLDataAll.mat"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-04 07:57:33--  https://monujohn.com/EEGdata/WLDataAll.mat\n",
            "Resolving monujohn.com (monujohn.com)... 198.136.51.114\n",
            "Connecting to monujohn.com (monujohn.com)|198.136.51.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42375907 (40M)\n",
            "Saving to: ‘WLDataAll.mat’\n",
            "\n",
            "WLDataAll.mat       100%[===================>]  40.41M  29.8MB/s    in 1.4s    \n",
            "\n",
            "2021-08-04 07:57:35 (29.8 MB/s) - ‘WLDataAll.mat’ saved [42375907/42375907]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDUpxdzfDCO"
      },
      "source": [
        "annots = loadmat('WLDataAll.mat')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hywJFcaWfO1e"
      },
      "source": [
        "data = annots['data']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9RtFPCCfjEg",
        "outputId": "5bf8a750-c00b-409e-f323-c10d3bc6f574"
      },
      "source": [
        "datapoint_array = []\n",
        "\n",
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "for datapoint in data:\n",
        "  datapoint = datapoint.T\n",
        "  data_squared = np.square(datapoint)\n",
        "  data_sum = data_squared.sum(axis=1)\n",
        "  \n",
        "  data_normalized = NormalizeData(data_sum)\n",
        "  datapoint_array.append(data_normalized)\n",
        "\n",
        "\n",
        "datapoint_array = np.array(datapoint_array)\n",
        "\n",
        "datapoint_array = datapoint_array.transpose()\n",
        "\n",
        "print('Latest array shape:', datapoint_array.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latest array shape: (360, 62)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NJUBr1xf26D",
        "outputId": "0da01def-35c0-4b42-dc54-04d1f72b009c"
      },
      "source": [
        "X = datapoint_array\n",
        "Y = annots['label'].transpose()\n",
        "\n",
        "Y = np.where(Y == 1, 0, Y)\n",
        "Y = np.where(Y == 2, 1, Y)\n",
        "\n",
        "print('X shape:', X.shape)\n",
        "print('Y shape:', Y.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape: (360, 62)\n",
            "Y shape: (360, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMR-olBugV_Y"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsOUTWRYgb6w"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(62,)),\n",
        "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
        "\tkeras.layers.Dense(16, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEXmh5C1gvHM",
        "outputId": "60f17938-a1d6-425f-cbe4-b4ed1c1c2750"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=1)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 1s 1ms/step - loss: 0.6990 - accuracy: 0.4444\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6947 - accuracy: 0.5119\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6955 - accuracy: 0.5198\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6937 - accuracy: 0.4960\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.5278\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.5357\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6891 - accuracy: 0.5238\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6843 - accuracy: 0.5595\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6783 - accuracy: 0.5873\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.6032\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.5754\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.6032\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.6111\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6389\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6270\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6071\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6548\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6429\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.6667\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6587\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6281 - accuracy: 0.6786\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6389\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6263 - accuracy: 0.6706\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6226 - accuracy: 0.6825\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6429\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.6706\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.6508\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6905\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6667\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.6865\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6984\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6984\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6786\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6865\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.6002 - accuracy: 0.6746\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.6984\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5967 - accuracy: 0.6984\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6865\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.6905\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.6905\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.6825\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.7103\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6905\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6984\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7063\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5760 - accuracy: 0.7063\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.7063\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6984\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.6944\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7063\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.7063\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.7143\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.7302\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7143\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.6984\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.6984\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7262\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7381\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.6865\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.6825\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7381\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.7183\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5514 - accuracy: 0.6984\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7222\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7302\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7302\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5483 - accuracy: 0.7143\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7262\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5362 - accuracy: 0.7222\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7262\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7262\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 0.7500\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5209 - accuracy: 0.7222\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.7302\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5243 - accuracy: 0.7262\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7341\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5263 - accuracy: 0.7222\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.7103\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5120 - accuracy: 0.7619\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7302\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7540\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7460\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7698\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5088 - accuracy: 0.7341\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7500\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7381\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7579\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7579\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7540\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7262\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7341\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7500\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7460\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7421\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7421\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7540\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7421\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7500\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.7619\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.6759\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY9WoqOxhO7W",
        "outputId": "c638b162-2943-4c72-f901-20d11315fb1d"
      },
      "source": [
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.6759259104728699\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}